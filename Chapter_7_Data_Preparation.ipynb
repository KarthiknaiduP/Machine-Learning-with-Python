{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Your Data For Machine Learning"
      ],
      "metadata": {
        "id": "OV6tpJlKzTAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this chapter  we see how to prepair data using skikit-learn\n",
        "\n",
        "things we will learn are\n",
        "1. Rescale data\n",
        "2. Standardlise data\n",
        "3. Normalise data\n",
        "4. Binarize data"
      ],
      "metadata": {
        "id": "18c3eLFP3Zj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets see why do we need to preprocess?\n",
        "\n",
        "You almost always need to pre-process your data. It is a required step. A difficulty is that different algorithms make different assumptions about your data and may require different transforms. Further, when you follow all of the rules and prepare your data, sometimes algorithms can deliver better results without pre-processing.\n",
        "\n",
        "\n",
        "Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to flush out which data transforms might be better at exposing the structure of your problem in general."
      ],
      "metadata": {
        "id": "WJLnNSjm35Dm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Rescale data**\n",
        "\n",
        "when data is comprising of variables in large varying scale, many ML models can benifit by rescalling this data to same scale usually between range 0 to 1.\n",
        "\n",
        "This is useful for optimization algorithms used in the core of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like k-Nearest Neighbors.\n",
        "\n",
        "You can rescale your data using scikit-learn using the\n",
        "\n",
        "**MinMaxScaler** class."
      ],
      "metadata": {
        "id": "wiZtseXy4HGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "filename = '/content/diabetes 2.csv'\n",
        "dataframe = read_csv(filename)\n",
        "array = dataframe.values\n",
        "# separate array into input and output components\n",
        "X = array[:,0:8] # 8 columns of features\n",
        "Y = array[:,8] # target column that is output\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5,:]) # printing the top 5 rows of the X tht is 8 features columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwGNU_8W7THI",
        "outputId": "84d25f66-3a11-47ec-a9ad-e6b67a69ab5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
            " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
            " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
            " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
            " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Standardlize data**\n",
        "\n",
        "\n",
        "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "it works better with rescaled data and then changes them into or tranfirms them into this so it is suitable for many algorithms witch gets beneficiary with this transformation,  such as linear regression, logistic regression and linear discriminate analysis\n",
        "\n",
        "You can standardize data using scikit-learn with the\n",
        "\n",
        "**StandardScaler** class."
      ],
      "metadata": {
        "id": "JywwKGeT9Twa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "b_rpGw_ZBP1c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5,:])\n",
        "\n",
        "#The values for each attribute now have a mean value of 0 and a standard deviation of 1."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoG-QcdPBRcD",
        "outputId": "95cd60fb-bb97-46e2-e8d1-9a44bc6d2b9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
            " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
            " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
            " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
            " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Normalize data***\n",
        "\n"
      ],
      "metadata": {
        "id": "Eas4_n9KBj8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(normalizedX[0:5,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucbTlyhQsEgU",
        "outputId": "58892f38-a122-4dec-e5e5-df0a51fbb402"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
            " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
            " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
            " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
            " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Binarize Data (Make Binary)"
      ],
      "metadata": {
        "id": "GUgY9xUgtqgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(binaryX[0:5,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN8JpJBQtsYG",
        "outputId": "55fe14cb-06d7-49a1-de76-565b3e9845fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
          ]
        }
      ]
    }
  ]
}